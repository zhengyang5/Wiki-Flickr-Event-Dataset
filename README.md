# Wiki-Flickr Event Dataset for Cross-modal Event Retrieval
This is to release the well-labeled but weakly-aligned dataset we collected for cross-modality event retrieval. The dataset consists of 28,825 images on Flickr and 11,960 text articles from hundreds of social media, belonging to 82 categories of events.

The links of the images are included and can be downloaded from the URLs.

Please cite the papers if you are using the dataset.

1. Zhenguo Yang, Zehang Lin, Peipei Kang, Jianming Lv, Qing Li, Wenyin Liu, "Learning Shared Semantic Space with Correlation Alignment for Cross-modal Event Retrieval", 2019. (Manuscript)

2. Runwei Situ, Zhenguo Yang*, Jianming Lv, Qing Li, Wenyin Liu, "Cross-Modal Event Retrieval: A Dataset and a Baseline using Deep Semantic Learning", In Proceedings of the Pacific-Rim Conference on Multimedia (PCM), 2018. 

For more information, please contact Zhenguo Yang. E-mail: zhengyang5-c@my.cityu.edu.hk
