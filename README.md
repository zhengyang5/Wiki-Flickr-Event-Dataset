# Wiki-Flickr Event Dataset for Cross-modal Event Retrieval
This is to release the well-labeled but weakly-aligned dataset we collected for cross-modality event retrieval. The dataset consists of 28,825 images on Flickr and 11,960 text articles from hundreds of social media, belonging to 82 categories of events.

The links of the images are included and can be downloaded from the URLs. (You can also download directly from this [URL](https://mail2gduteducn-my.sharepoint.com/:u:/g/personal/2111605074_mail2_gdut_edu_cn/EVjoelOI1MlDvEXvB9wheqkB5MSk70dESi3aqh7URyVc9Q).)

Please cite the papers if you are using the dataset.

1. Zhenguo Yang, Zehang Lin, Peipei Kang, Jianming Lv, Qing Li, Wenyin Liu, "Learning Shared Semantic Space with Correlation Alignment for Cross-modal Event Retrieval", arXiv:1901.04268, 2019.

2. Runwei Situ, Zhenguo Yang*, Jianming Lv, Qing Li, Wenyin Liu, "Cross-Modal Event Retrieval: A Dataset and a Baseline using Deep Semantic Learning", In Proceedings of the Pacific-Rim Conference on Multimedia (PCM), 2018. 

For any question regarding the dataset, please contact Dr. Zhenguo Yang (zhengyang5-c@my.cityu.edu.hk). The raw images can be obtained via sending a request email to us. Specifically, the researchers interested in the dataset should download and fill up the **Dataset Agreement Form** and send it back to us.
